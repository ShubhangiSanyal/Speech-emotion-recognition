# Speech-emotion-recognition
End-to-End Speech Emotion Recognition Project using various datasets to classify speech audio into different categories of emotions.

## Datasets used: 
- "[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)" by Livingstone & Russo is licensed under CC BY-NA-SC 4.0.
- "[CREMA-D](https://www.kaggle.com/datasets/ejlok1/cremad)" by [David Cooper Cheyney](https://github.com/CheyneyComputerScience/CREMA-D)
- "[Surrey Audio-Visual Expressed Emotion (SAVEE)](https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee)" by [University of Surrey](http://kahlan.eps.surrey.ac.uk/savee/Database.html).
- "[Toronto emotional speech set (TESS)](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess)" by [University of Toronto](https://tspace.library.utoronto.ca/handle/1807/24487).

## Emotion Categories:
| Code | Emotion |   | Code | Emotion |
|------|---------|:-:|------|---------|
| 1    | Neutral |   | 5    | Angry   |
| 2    | Calm    |   | 6    | Fear    |
| 3    | Happy   |   | 7    | Disgust |
| 4    | Sad     |   | 8    | Surprise|

## Models experimented with:
- CNN
- Transformer

<br> Best model deployed locally using **Streamlit**.

## Contributing members:
- [Saikat Bera](https://github.com/berasaikat)
- [Shreyan Chakraborty](https://github.com/shreyanc07)
- [Sayantan Mondal](https://github.com/msayantanm)
- [Shubhangi Sanyal](https://github.com/ShubhangiSanyal)
